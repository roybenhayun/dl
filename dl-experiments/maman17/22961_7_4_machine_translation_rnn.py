# -*- coding: utf-8 -*-
"""Copy of 22961_7_4_machine_translation_RNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yKLJintU-an9PlB2MLq_lLGn0pSmCeP1
"""



import torch
from torch import nn
import torch.nn.functional as F
import datasets as ds

src = "en"
tgt = "fr"
dataset = ds.load_dataset("tatoeba", lang1=src, lang2=tgt)
print(dataset)

pairs_list = dataset["train"]["translation"]

print(pairs_list[10])
print(pairs_list[11])
print(pairs_list[12])

print(pairs_list[20])
print(pairs_list[23])
print(pairs_list[25])


total = len(pairs_list)
src_sents_unfiltered = [x[src].split() for x in pairs_list]  # split text to single words
tgt_sents_unfiltered = [x[tgt].split() for x in pairs_list]
print(src_sents_unfiltered[10])
print(tgt_sents_unfiltered[10])

MAX_length = 5
filter = lambda idx: len(src_sents_unfiltered[idx]) <= MAX_length and \
                     len(tgt_sents_unfiltered[idx]) <= MAX_length
mask = map(filter, range(total))
src_sents = [x for idx,x in enumerate(src_sents_unfiltered) if filter(idx)]
tgt_sents = [x for idx,x in enumerate(tgt_sents_unfiltered) if filter(idx)]
print(src_sents[10])
print(tgt_sents[10])

#Shuffle the data
torch.manual_seed(0)
shuffle_idxs = torch.randperm(len(src_sents))
def shuffle(my_list):
  extract_one   = lambda x: my_list[shuffle_idxs[x]]
  shuffled_list = list(map(extract_one,range(len(my_list))))
  return shuffled_list
src_sents = shuffle(src_sents)
tgt_sents = shuffle(tgt_sents)
print(src_sents[10])
print(tgt_sents[10])

for idx in range(len(src_sents)):
  src_sents[idx].append("<END>")  # add END token in input sentence
  tgt_sents[idx] = ["<START>"]+tgt_sents[idx]+["<END>"]  # add START,END tokens in input sentence

from torchtext.vocab import build_vocab_from_iterator
# build_vocab_from_iterator: map word to integer TOKEN
src_vocab = build_vocab_from_iterator(src_sents, specials=["<UNK>","<END>"])
src_vocab.set_default_index(0)  # default index for unknowns (mapped to <UNK> above)
print(len(src_vocab))
tgt_vocab = build_vocab_from_iterator(tgt_sents, specials=["<UNK>","<END>","<START>"])
tgt_vocab.set_default_index(0)
print(len(tgt_vocab))

src_tokens = list(map(lambda x: torch.tensor(src_vocab(x)), src_sents))  # map source sentences to tokens
tgt_tokens = list(map(lambda x: torch.tensor(tgt_vocab(x)), tgt_sents))  # map target sentences to tokens

print(f"src_sents: {src_sents[0]}, src_tokens: {src_tokens[0]}")
print(f"tgt_sents: {tgt_sents[0]}, tgt_tokens: {tgt_tokens[0]}")

START_Token = torch.tensor(tgt_vocab(["<START>"])[0])
END_Token   = torch.tensor(tgt_vocab(["<END>"])[0])
print(START_Token, END_Token)
UNK_token = torch.tensor(tgt_vocab(["<UNK>"]))
print(f"tgt <UNK>: { UNK_token}")
START_token = torch.tensor(tgt_vocab(["<START>"]))
print(f"tgt <UNK>: { START_token}")
END_token = torch.tensor(tgt_vocab(["<END>"]))
print(f"tgt <END>: { END_token}")


print(f"first 15 tokens in tgt_vocab: {tgt_vocab.get_itos()[0:15]}")
print(f"first 15 tokens in src_vocab: {src_vocab.get_itos()[0:15]}")

print("Source:", src_sents[0], src_tokens[0], sep="\n")
print("Target:", tgt_sents[0], tgt_tokens[0], sep="\n")

# TODO: compare to FasterDeepRNNClassifier in unit 6
class Encoder(nn.Module):
    def __init__(self, embed_dim, hidden_dim, RNNlayers):
        super().__init__()
        self.src_embedding  = nn.Embedding(len(src_vocab), embed_dim)  # map Integer tokens to Vectors
        self.rnn_stack      = nn.LSTM(embed_dim,
                                 hidden_dim,
                                 RNNlayers)
    def forward(self, src_tokens):
      all_embeddings         = self.src_embedding(src_tokens)  # get Embeddings for all source Integer tokens
      all_embeddings         = all_embeddings.unsqueeze(1)  # fake batch
      hidden_state_history, _= self.rnn_stack(all_embeddings)
      context                = hidden_state_history[-1,0,:]  # the last H is called Context
      return context

class DecoderRNNCell(nn.Module):
    def __init__(self, embed_dim, hidden_dim):
        super().__init__()
        self.hidden_state  = torch.zeros(hidden_dim)
        self.RNNcell       = nn.RNNCell(embed_dim, hidden_dim)  # TBD: need to flip?
        self.output_linear = nn.Linear(in_features=hidden_dim,
                                  out_features=len(tgt_vocab))  # the output features is the size of the Vocabulary
        self.logsoftmax    = nn.LogSoftmax(dim=0)

    def forward(self, one_embedded_token):
        new_state          = self.RNNcell(one_embedded_token,
                                           self.hidden_state)
        tgt_token_scores   = self.output_linear(new_state)  # size of Vocabulary
        tgt_token_logprobs = self.logsoftmax(tgt_token_scores)  # probability of every Integer Token in the Vocabulary
        self.hidden_state = new_state
        return tgt_token_logprobs

# Decoder for Training
class TrainingDecoder(nn.Module):
    def __init__(self, embed_dim, hidden_dim):
        super().__init__()
        self.tgt_embedding  = nn.Embedding(len(tgt_vocab), embed_dim)  # Embedding of target language
        self.RNNcell        = DecoderRNNCell(embed_dim, hidden_dim)

    def forward(self, context, tgt_tokens):
      self.RNNcell.hidden_state = context  # initialize hidden_state with Context (Encoder output)
      translated_tokens = [START_Token]  # signal <START>
      sentence_loss = 0
      hits = 0
      for idx in range(len(tgt_tokens)-1):  # IMPL-NOTE: tgt_tokens used to calc loss only
        ##Teacher forcing:
        #previous_token  = tgt_tokens[idx]
        previous_token  = translated_tokens[idx]
        embedded_token  = self.tgt_embedding(previous_token)  # get Embedding for prev token
        logprobs        = self.RNNcell(embedded_token)  # the probability per each tgt_embedding tokens
        predicted_token = logprobs.argmax()  # index of tgt_embedding with max prob
        translated_tokens.append(predicted_token.detach())  # append to target sentence (the above, index of tgt_embedding token)

        correct_token   = tgt_tokens[idx+1]                 #  compare with correct token
        if correct_token == predicted_token:
            hits += 1
        token_loss      = -logprobs[correct_token]          # IMPL-NOTE: tgt_tokens used to calc loss only
        sentence_loss  += token_loss                        #

        if predicted_token == END_Token:
          break
      # print(f"{hits} / {len(tgt_tokens)}")
      return translated_tokens, sentence_loss, (hits / len(tgt_tokens))

class TrainingTranslator(nn.Module):
      def __init__(self, embed_dim, hidden_dim, encoder_layers):
        super().__init__()
        self.encoder = Encoder(embed_dim, hidden_dim, encoder_layers)
        self.decoder = TrainingDecoder(embed_dim, hidden_dim)
      def forward(self, src_tokens, tgt_tokens):
        context = self.encoder(src_tokens)
        return self.decoder(context, tgt_tokens)

"""#Eval Mode"""

# Decoder for Eval
class Decoder(TrainingDecoder):
    def __init__(self, embed_dim, hidden_dim):
        super().__init__(embed_dim, hidden_dim)
    def forward(self,context, tgt_tokens=None, max_tokens=10):
      if self.training:
        return super().forward(context, tgt_tokens)  # IMPL-NOTE: tgt_tokens used to calc loss only
      else:
        with torch.no_grad():
          self.RNNcell.hidden_state = context
          translated_tokens = [START_Token]
          current_token = translated_tokens[0]
          for _ in range(max_tokens):
            embedded_token  = self.tgt_embedding(current_token)
            logprobs        = self.RNNcell(embedded_token)
            predicted_token = logprobs.argmax()  # get predicted with max value
            translated_tokens.append(predicted_token.detach())
            if predicted_token == END_Token:
              break  # gets here frequently with under-trained model
            current_token   = predicted_token  # update current_token based on last prediction
        return translated_tokens

# Translator for Eval (Training Decoder also, see [T1])
class Translator(nn.Module):
      def __init__(self, embed_dim, hidden_dim,encoder_layers):
        super().__init__()
        self.encoder = Encoder(embed_dim, hidden_dim, encoder_layers)
        self.decoder = Decoder(embed_dim, hidden_dim)
      def forward(self,src_tokens, tgt_tokens=None, corrupted_src_tokens=None):
        # 1. get Context from Encoder
        if corrupted_src_tokens != None:
            context = self.encoder(corrupted_src_tokens)  # DAE IMPL-NOTE: the Context is now "corrupted"
        else:
            context = self.encoder(src_tokens)
        # 1. run Decoder with Context
        if self.training:  # [T1]
          out=self.decoder(context, tgt_tokens)  # DAE IMPL-NOTE: tgt_tokens used to calc loss, in both AE and DAE.
        else:
          out=self.decoder(context)
        return out

"""#Training"""

# train on one pair of src-target sentence
def iterate_one_pair(src_tokens, tgt_tokens):
    model.train()
    optimizer.zero_grad()
    output, loss, hits = model(src_tokens, tgt_tokens)
    loss.backward()
    optimizer.step()
    return loss.detach(), hits

def iterate_one_pair_DAE(src_tokens, tgt_tokens, corrupted_src_tokens):
    model.train()
    optimizer.zero_grad()
    output, loss, hits = model(src_tokens, tgt_tokens, corrupted_src_tokens)  # IMPL-NOTE: tgt_tokens used to calc loss down the stream
    loss.backward()
    optimizer.step()
    return loss.detach(), hits

sparsity_factor = 1.2  # increase in hidden state for sparsity
model     = Translator(50, int(50 * sparsity_factor), 2)
optimizer = torch.optim.AdamW(model.parameters())

print("-------------------------------------")
print("train eval")
print("-------------------------------------")


def get_corrupted_src_tokens(src_tokens):
    # return src_tokens
    rand_idx = torch.randint(low=0, high=len(src_tokens) - 1, size=(1,1)).item() # note the last token in src is the END token
    corrupted_src_tokens = src_tokens.clone().detach()  # create a copy
    corrupted_src_tokens[rand_idx] = torch.tensor(src_vocab(["<UNK>"]))  # "corrupt\zero 20%" ~= 1 out of 5 words is UNKNOWN
    return corrupted_src_tokens

#overfit a small batch to check if learning _can_ occur
num_samples, epochs = 10, 100
for epoch in range(epochs):
  batch_loss_agg = torch.tensor([0.])
  hits = 0
  for idx in range(num_samples):
    # run model on a sentence and translation - Integer tokens of src_sents[idx], tgt_sents[idx]
    corrupted_src_tokens = get_corrupted_src_tokens(src_tokens[idx])
    loss, hit = iterate_one_pair_DAE(src_tokens[idx], tgt_tokens[idx], corrupted_src_tokens)
    hits += hit
    batch_loss_agg += loss
  epoch_loss = batch_loss_agg / num_samples
  if epoch % 10 == 0:
    print("Epoch", epoch, " loss:", epoch_loss.item(), " Hits: ", hits / num_samples)

print("-------------------------------------")
print("model eval with known sentences")
print("-------------------------------------")

def calc_accuracy(predicted, ground_truth):
    predicted = predicted[1:-1]  # ignore <START>, <END>
    ground_truth = ground_truth[1:-1]  # ignore <START>, <END>
    same_len = len(predicted) == len(ground_truth)
    hits = 0
    for idx, expected_word in enumerate(ground_truth):
        if len(predicted) > idx and predicted[idx] == expected_word:
            hits = hits + 1
    return same_len, hits / len(ground_truth)


model.eval()
with torch.no_grad():
  for idx in range(num_samples):
    corrupted_src_tokens = get_corrupted_src_tokens(src_tokens[idx])
    a = model(corrupted_src_tokens)
    predicted_itos = [tgt_vocab.get_itos()[x.item()] for x in a]
    ground_truth   = [tgt_vocab.get_itos()[x.item()] for x in tgt_tokens[idx]]
    same_len, acc = calc_accuracy(predicted_itos, ground_truth)
    print(f"predicted: {predicted_itos}, ground_truth: {ground_truth}, [len: {same_len}, acc: {acc}]")

print("-------------------------------------")
print("model eval with unknown sentences")
print("-------------------------------------")

with torch.no_grad():
  for idx in range(num_samples, num_samples+5):
    corrupted_src_tokens = get_corrupted_src_tokens(src_tokens[idx])
    a = model(corrupted_src_tokens)
    predicted_itos = [tgt_vocab.get_itos()[x.item()] for x in a]
    ground_truth   = [tgt_vocab.get_itos()[x.item()] for x in tgt_tokens[idx]]
    same_len, acc = calc_accuracy(predicted_itos, ground_truth)
    print(f"predicted: {predicted_itos}, ground_truth: {ground_truth}, [len: {same_len}, acc: {acc}]")


