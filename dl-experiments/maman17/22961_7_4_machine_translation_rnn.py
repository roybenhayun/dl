# -*- coding: utf-8 -*-
"""Copy of 22961_7_4_machine_translation_RNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yKLJintU-an9PlB2MLq_lLGn0pSmCeP1
"""



import torch
from torch import nn
import torch.nn.functional as F
import datasets as ds

src = "en"
tgt = "fr"
dataset = ds.load_dataset("tatoeba", lang1=src, lang2=tgt)
print(dataset)

print(dataset["train"]["translation"][10])
print(dataset["train"]["translation"][11])
print(dataset["train"]["translation"][12])

print(dataset["train"]["translation"][20])
print(dataset["train"]["translation"][23])
print(dataset["train"]["translation"][25])

pairs_list = dataset["train"]["translation"]
total = len(pairs_list)
src_sents_unfiltered = [x[src].split() for x in pairs_list]  # split text to single words
tgt_sents_unfiltered = [x[tgt].split() for x in pairs_list]
print(src_sents_unfiltered[10])
print(tgt_sents_unfiltered[10])

MAX_length = 5
filter = lambda idx: len(src_sents_unfiltered[idx]) <= MAX_length and \
                     len(tgt_sents_unfiltered[idx]) <= MAX_length
mask = map(filter, range(total))
src_sents = [x for idx,x in enumerate(src_sents_unfiltered) if filter(idx)]
tgt_sents = [x for idx,x in enumerate(tgt_sents_unfiltered) if filter(idx)]
print(src_sents[10])
print(tgt_sents[10])

#Shuffle the data
torch.manual_seed(0)
shuffle_idxs = torch.randperm(len(src_sents))
def shuffle(my_list):
  extract_one   = lambda x: my_list[shuffle_idxs[x]]
  shuffled_list = list(map(extract_one,range(len(my_list))))
  return shuffled_list
src_sents = shuffle(src_sents)
tgt_sents = shuffle(tgt_sents)
print(src_sents[10])
print(tgt_sents[10])

for idx in range(len(src_sents)):
  src_sents[idx].append("<END>")  # add END token in input sentence
  tgt_sents[idx] = ["<START>"]+tgt_sents[idx]+["<END>"]  # add START,END tokens in input sentence

from torchtext.vocab import build_vocab_from_iterator
# build_vocab_from_iterator maps every word to a single TOKEN
src_vocab = build_vocab_from_iterator(src_sents, specials=["<UNK>","<END>"])
src_vocab.set_default_index(0)  # default index for unknowns (mapped to <UNK> above)
print(len(src_vocab))
tgt_vocab = build_vocab_from_iterator(tgt_sents, specials=["<UNK>","<END>","<START>"])
tgt_vocab.set_default_index(0)
print(len(tgt_vocab))

src_tokens = list(map(lambda x: torch.tensor(src_vocab(x)), src_sents))  # map source sentences to tokens
tgt_tokens = list(map(lambda x: torch.tensor(tgt_vocab(x)), tgt_sents))  # map target sentences to tokens

print(f"src_sents: {src_sents[0]}, src_tokens: {src_tokens[0]}")
print(f"tgt_sents: {tgt_sents[0]}, tgt_tokens: {tgt_tokens[0]}")

START_Token = torch.tensor(tgt_vocab(["<START>"])[0])
END_Token   = torch.tensor(tgt_vocab(["<END>"])[0])
print(START_Token, END_Token)
UNK_token = torch.tensor(tgt_vocab(["<UNK>"]))
print(f"tgt <UNK>: { UNK_token}")
END_token = torch.tensor(tgt_vocab(["<END>"]))
print(f"tgt <END>: { END_token}")
START_token = torch.tensor(tgt_vocab(["<START>"]))
print(f"tgt <UNK>: { START_token}")


print(tgt_vocab.get_itos()[0:15])
print(src_vocab.get_itos()[0:15])

print("Source:", src_sents[0], src_tokens[0], sep="\n")
print("Target:", tgt_sents[0], tgt_tokens[0], sep="\n")

# TODO: compare to FasterDeepRNNClassifier in unit 6
class Encoder(nn.Module):
    def __init__(self, embed_dim, hidden_dim, RNNlayers):
        super().__init__()
        self.src_embedding  = nn.Embedding(len(src_vocab), embed_dim)  # map Integer tokens to Vectors
        self.rnn_stack      = nn.LSTM(embed_dim,
                                 hidden_dim,
                                 RNNlayers)
    def forward(self, src_tokens):
      all_embeddings         = self.src_embedding(src_tokens)  # get Embeddings for all source Integer tokens
      all_embeddings         = all_embeddings.unsqueeze(1)  # fake batch
      hidden_state_history, _= self.rnn_stack(all_embeddings)
      context                = hidden_state_history[-1,0,:]  # the last H is called Context
      return context

class DecoderRNNCell(nn.Module):
    def __init__(self, embed_dim, hidden_dim):
        super().__init__()
        self.hidden_state  = torch.zeros(hidden_dim)
        self.RNNcell       = nn.RNNCell(embed_dim, hidden_dim)
        self.output_linear = nn.Linear(in_features=hidden_dim,
                                  out_features=len(tgt_vocab))
        self.logsoftmax    = nn.LogSoftmax(dim=0)

    def forward(self, one_embedded_token):
        new_state          = self.RNNcell(one_embedded_token,
                                           self.hidden_state)
        tgt_token_scores   = self.output_linear(new_state)
        tgt_token_logprobs = self.logsoftmax(tgt_token_scores)
        self.hidden_state = new_state
        return tgt_token_logprobs

# Decoder for Training
class TrainingDecoder(nn.Module):
    def __init__(self, embed_dim, hidden_dim):
        super().__init__()
        self.tgt_embedding  = nn.Embedding(len(tgt_vocab), embed_dim)  # Embedding of target language
        self.RNNcell        = DecoderRNNCell(embed_dim, hidden_dim)

    def forward(self, context, tgt_tokens):
      self.RNNcell.hidden_state = context  # initialize hidden_state with Context (Encoder output)
      translated_tokens = [START_Token]  # signal <START>
      sentence_loss = 0
      for idx in range(len(tgt_tokens)-1):
        ##Teacher forcing:
        #previous_token  = tgt_tokens[idx]
        previous_token  = translated_tokens[idx]
        embedded_token  = self.tgt_embedding(previous_token)  # get Embedding for prev token
        logprobs        = self.RNNcell(embedded_token)  # the probability per each tgt_embedding tokens
        predicted_token = logprobs.argmax()  # index of tgt_embedding with max prob
        translated_tokens.append(predicted_token.detach())  # append to target sentence (the above, index of tgt_embedding token)

        correct_token   = tgt_tokens[idx+1]                 #  compare with correct token
        token_loss      = -logprobs[correct_token]          #
        sentence_loss  += token_loss                        #

        if predicted_token == END_Token:
          break
      return translated_tokens, sentence_loss, correct_token == predicted_token

class TrainingTranslator(nn.Module):
      def __init__(self, embed_dim, hidden_dim, encoder_layers):
        super().__init__()
        self.encoder = Encoder(embed_dim, hidden_dim, encoder_layers)
        self.decoder = TrainingDecoder(embed_dim, hidden_dim)
      def forward(self, src_tokens, tgt_tokens):
        context = self.encoder(src_tokens)
        return self.decoder(context, tgt_tokens)

"""#Eval Mode"""

# Decoder for Eval
class Decoder(TrainingDecoder):
    def __init__(self, embed_dim, hidden_dim):
        super().__init__(embed_dim, hidden_dim)
    def forward(self,context, tgt_tokens=None, max_tokens=10):
      if self.training:
        return super().forward(context, tgt_tokens)
      else:
        with torch.no_grad():
          self.RNNcell.hidden_state = context
          translated_tokens = [START_Token]
          current_token = translated_tokens[0]
          for _ in range(max_tokens):
            embedded_token  = self.tgt_embedding(current_token)
            logprobs        = self.RNNcell(embedded_token)
            predicted_token = logprobs.argmax()  # get predicted with max value
            translated_tokens.append(predicted_token.detach())
            if predicted_token == END_Token:
              break
            current_token   = predicted_token  # update current_token based on last prediction
        return translated_tokens

# Translator for Eval (Training Decoder also, see [T1])
class Translator(nn.Module):
      def __init__(self, embed_dim, hidden_dim,encoder_layers):
        super().__init__()
        self.encoder = Encoder(embed_dim, hidden_dim, encoder_layers)
        self.decoder = Decoder(embed_dim, hidden_dim)
      def forward(self,src_tokens, tgt_tokens=None):
        context = self.encoder(src_tokens)  # get Context from Encoder
        if self.training:  # [T1]
          out=self.decoder(context, tgt_tokens)
        else:
          out=self.decoder(context)
        return out

"""#Training"""

# train on one pair of src-target sentence
def iterate_one_pair(src_tokens, tgt_tokens):
    model.train()
    optimizer.zero_grad()
    output, loss, hit = model(src_tokens, tgt_tokens)
    loss.backward()
    optimizer.step()
    return loss.detach(), hit

model     = Translator(50,50,2)
optimizer = torch.optim.AdamW(model.parameters())

#overfit a small batch to check if learning _can_ occur
num_samples, epochs = 10, 200
for epoch in range(epochs):
  batch_loss_agg = torch.tensor([0.])
  hits = 0
  for idx in range(num_samples):
    # run model on a sentence and translation - Integer tokens of src_sents[idx], tgt_sents[idx]
    loss, hit = iterate_one_pair(src_tokens[idx], tgt_tokens[idx])
    if hit:
        hits += 1
    batch_loss_agg += loss
  epoch_loss = batch_loss_agg / num_samples
  if epoch % 2 == 0:
    print("Epoch", epoch, " loss:", epoch_loss.item(), " Hits: ", hits)

model.eval()
with torch.no_grad():
  for idx in range(num_samples):
    a = model(src_tokens[idx])
    predicted_itos = [tgt_vocab.get_itos()[x.item()] for x in a]
    ground_truth   = [tgt_vocab.get_itos()[x.item()] for x in tgt_tokens[idx]]
    print(predicted_itos, ground_truth)

with torch.no_grad():
  for idx in range(num_samples, num_samples+5):
    a = model(src_tokens[idx])
    predicted_itos = [tgt_vocab.get_itos()[x.item()] for x in a]
    ground_truth   = [tgt_vocab.get_itos()[x.item()] for x in tgt_tokens[idx]]
    print(predicted_itos,ground_truth)